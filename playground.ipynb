{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from costly import Costlog\n",
    "from solib.utils import *\n",
    "from solib.llm_utils import *\n",
    "from solib.protocols.common import *\n",
    "from solib.protocols.debate import *\n",
    "from solib.protocols.consultancy import *\n",
    "from solib.protocols.variants.common import *\n",
    "from solib.protocols.variants.debate import *\n",
    "from solib.protocols.variants.consultancy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (5.2.0)/charset_normalizer (2.0.10) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'cost_min': 0.0005500500000000001, 'cost_max': 0.0005500500000000001, 'time_min': 30.3148230999941, 'time_max': 30.3148230999941, 'input_tokens': 35, 'output_tokens': 908, 'output_tokens_min': 908, 'output_tokens_max': 908, 'calls': 1, 'model': 'gpt-4o-mini', 'simulated': False, 'input_string': None, 'messages': None, 'output_string': 'The Riemann Hypothesis is one of the most famous and long-standing unsolved problems in mathematics, specifically in number theory and complex analysis. It is concerned with the distribution of prime numbers and is deeply connected to the properties of the Riemann zeta function.\\n\\n### Prerequisites\\n\\nTo understand the Riemann Hypothesis in detail, you should be familiar with the following concepts:\\n\\n1. **Complex Analysis**: Understanding complex functions, analytic continuation, and the concept of meromorphic functions.\\n2. **Number Theory**: Familiarity with prime numbers, the distribution of primes, and the concept of the Euler product.\\n3. **Fourier Analysis**: Basic knowledge of Fourier series and transforms, particularly in relation to periodic functions.\\n4. **Analytic Functions**: Understanding of poles, residues, and the argument principle.\\n\\n### The Riemann Zeta Function\\n\\nThe Riemann zeta function \\\\(\\\\zeta(s)\\\\) is defined for complex numbers \\\\(s\\\\) with real part greater than 1 by the series:\\n\\n\\\\[\\n\\\\zeta(s) = \\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^s}\\n\\\\]\\n\\nThis series converges for \\\\(\\\\text{Re}(s) > 1\\\\). The zeta function can be analytically continued to other values of \\\\(s\\\\) (except for \\\\(s = 1\\\\), where it has a simple pole) using various techniques, including the use of the Euler product formula:\\n\\n\\\\[\\n\\\\zeta(s) = \\\\prod_{p \\\\text{ prime}} \\\\frac{1}{1 - p^{-s}}\\n\\\\]\\n\\nfor \\\\(\\\\text{Re}(s) > 1\\\\). This product representation connects the zeta function to the distribution of prime numbers.\\n\\n### Analytic Continuation and Functional Equation\\n\\nThe zeta function can be analytically continued to the entire complex plane except for \\\\(s = 1\\\\). It satisfies a functional equation:\\n\\n\\\\[\\n\\\\zeta(s) = 2^s \\\\pi^{s-1} \\\\sin\\\\left(\\\\frac{\\\\pi s}{2}\\\\right) \\\\Gamma(1-s) \\\\zeta(1-s)\\n\\\\]\\n\\nwhere \\\\(\\\\Gamma(s)\\\\) is the gamma function. This functional equation relates values of the zeta function at \\\\(s\\\\) and \\\\(1-s\\\\).\\n\\n### Non-Trivial Zeros\\n\\nThe Riemann Hypothesis specifically concerns the non-trivial zeros of the zeta function, which are the solutions to the equation:\\n\\n\\\\[\\n\\\\zeta(s) = 0\\n\\\\]\\n\\nThe trivial zeros of the zeta function occur at the negative even integers: \\\\(s = -2, -4, -6, \\\\ldots\\\\). The non-trivial zeros are located in the critical strip where \\\\(0 < \\\\text{Re}(s) < 1\\\\).\\n\\n### The Riemann Hypothesis Statement\\n\\nThe Riemann Hypothesis asserts that all non-trivial zeros of the Riemann zeta function lie on the \"critical line\" in the complex plane, defined by:\\n\\n\\\\[\\n\\\\text{Re}(s) = \\\\frac{1}{2}\\n\\\\]\\n\\nIn other words, if \\\\(s = \\\\sigma + it\\\\) is a non-trivial zero of \\\\(\\\\zeta(s)\\\\), then the hypothesis states that:\\n\\n\\\\[\\n\\\\sigma = \\\\frac{1}{2}\\n\\\\]\\n\\n### Implications of the Riemann Hypothesis\\n\\nThe Riemann Hypothesis has profound implications for number theory, particularly in the distribution of prime numbers. The prime number theorem, which describes the asymptotic distribution of primes, can be refined using the Riemann Hypothesis. Specifically, it implies that the error term in the prime number theorem can be significantly improved.\\n\\n### Current Status\\n\\nAs of now, the Riemann Hypothesis remains unproven, despite extensive numerical evidence supporting it. Many non-trivial zeros have been computed, and all of them lie on the critical line, consistent with the hypothesis. The hypothesis is one of the seven \"Millennium Prize Problems,\" with a reward of one million dollars for a correct proof or counterexample.\\n\\n### Conclusion\\n\\nThe Riemann Hypothesis is a central question in mathematics that connects various fields, including number theory, complex analysis, and mathematical physics. Its resolution would not only advance our understanding of prime numbers but also have far-reaching consequences across mathematics.', 'description': None}]\n"
     ]
    }
   ],
   "source": [
    "ce = Costlog()\n",
    "x = get_llm_response(\n",
    "    prompt=\"Explain the Riemann Hypothesis to me in full mathematical detail, including all necessary prerequisites. Assume I have a strong background in mathematics.\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    simulate=False,\n",
    "    cost_log=ce,\n",
    ")\n",
    "print(ce.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = Question(\n",
    "    question = 'Who will be the 2024 presidential winner?',\n",
    "    possible_answers=[Answer('A', 'Donald Trump'), Answer('B', 'not Donald Trump')],\n",
    "    correct_answer=Answer('A', 'Donald Trump'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Who will be the 2024 presidential winner?\n",
      "POSSIBLE ANSWERS:\n",
      "A: Donald Trump\n",
      "B: not Donald Trump\n",
      "## ARGUMENTS MADE SO FAR:\n",
      "\n",
      "### ARGUMENT FOR A:\n",
      "The 2024 presidential election is poised to be a pivotal moment in American history, and there are compelling reasons to believe that Donald Trump will emerge as the winner. \n",
      "\n",
      "First and foremost, Trump's base remains incredibly loyal and energized. Despite the controversies and challenges he has faced, his supporters have consistently demonstrated unwavering commitment. This loyalty is not just a fleeting sentiment; it is a deeply ingrained belief in his vision for America. In a political landscape where voter turnout can be the deciding factor, Trump's ability to mobilize his base gives him a significant advantage.\n",
      "\n",
      "Moreover, the current political climate is ripe for Trump's return. Economic concerns, including inflation and job security, are at the forefront of voters' minds. Many Americans feel disillusioned with the current administration's handling of these issues. Trump has a proven track record of appealing to voters' economic anxieties, and his promises to restore jobs and stimulate growth resonate strongly with those who feel left behind. His message of \"Make America Great Again\" taps into a nostalgic yearning for a time when many felt more secure and prosperous.\n",
      "\n",
      "Additionally, Trump's media presence and ability to dominate the news cycle cannot be underestimated. He has a unique talent for capturing public attention, whether through rallies, social media, or interviews. This visibility not only keeps him relevant but also allows him to shape the narrative around the election. In an era where perception often outweighs reality, Trump's ability to control the conversation gives him a strategic edge over his opponents.\n",
      "\n",
      "Furthermore, the Democratic Party faces its own internal challenges. With a divided electorate and varying opinions on key issues, the party may struggle to present a unified front against Trump. If the Democrats cannot effectively rally their base and present a compelling alternative, they risk handing Trump the opportunity to capitalize on their disarray.\n",
      "\n",
      "Lastly, historical trends suggest that incumbents or former presidents often have an advantage in elections. Trump's previous experience in office, combined with his name recognition and established political brand, positions him favorably against any challengers. Voters often gravitate towards familiarity, especially in uncertain times, and Trump's status as a former president could sway undecided voters who prioritize stability.\n",
      "\n",
      "In conclusion, the combination of Trump's loyal base, the current political and economic climate, his media prowess, the challenges facing the Democratic Party, and historical trends all point to a strong likelihood that Donald Trump will be the 2024 presidential winner. His ability to connect with voters and address their concerns makes him a formidable candidate, and as the election approaches, it is clear that he is a force to be reckoned with.\n",
      "### ARGUMENT FOR B:\n",
      "The 2024 presidential election is shaping up to be a critical juncture for the United States, and there are several compelling reasons to believe that the winner will not be Donald Trump. \n",
      "\n",
      "First and foremost, the political landscape has evolved significantly since Trump's presidency. Many voters are seeking change and are disillusioned with the divisive politics that characterized his time in office. The growing demographic shifts in the electorate, particularly among younger voters and diverse communities, indicate a strong desire for a candidate who embodies inclusivity and progress. This shift could lead to a significant backlash against Trump, as voters may prioritize unity and a forward-looking vision over nostalgia for the past.\n",
      "\n",
      "Moreover, Trump's legal challenges and controversies continue to loom large. As he faces multiple indictments and ongoing investigations, these issues could alienate moderate voters who are concerned about the implications of his legal troubles. The perception of instability and chaos surrounding his candidacy may deter undecided voters who prioritize integrity and stability in leadership. In a time when many Americans are yearning for a sense of normalcy, Trump's legal entanglements could serve as a significant liability.\n",
      "\n",
      "Additionally, the Democratic Party, despite its internal challenges, has a strong opportunity to present a compelling alternative to Trump. With a diverse field of candidates and a renewed focus on key issues such as healthcare, climate change, and social justice, the Democrats can effectively mobilize their base and appeal to independent voters. The party's ability to unite around a candidate who resonates with the electorate's concerns could prove to be a decisive factor in the election outcome.\n",
      "\n",
      "Furthermore, the impact of grassroots movements and activism cannot be underestimated. The rise of organizations focused on voter registration, turnout, and advocacy for progressive policies has energized many Americans who are eager for change. This grassroots momentum could translate into higher voter turnout, particularly among demographics that traditionally lean Democratic. If these movements successfully engage and mobilize voters, it could create a formidable challenge for Trump.\n",
      "\n",
      "Lastly, historical trends indicate that elections often favor candidates who can adapt to the changing sentiments of the electorate. Trump's polarizing nature may hinder his ability to attract swing voters, especially in battleground states where elections are often decided by a small margin. If the opposition can effectively communicate a vision that resonates with the electorate's aspirations, it could lead to a decisive victory against Trump.\n",
      "\n",
      "In conclusion, the combination of shifting demographics, Trump's legal challenges, the potential for a strong Democratic alternative, grassroots activism, and historical trends all suggest that the 2024 presidential winner is unlikely to be Donald Trump. As the election approaches, the desire for change and a unifying vision may ultimately prevail, paving the way for a candidate who can address the pressing issues facing the nation and inspire hope for the future.\n",
      "## JUDGE PROBABILITY ESTIMATES:\n",
      "{'A': 1.0677030272546973e-06, 'B': 0.9999989322969728}\n",
      "## JUDGE PROBABILITY ESTIMATES:\n",
      "{'A': 1.0677030272546973e-06, 'B': 0.9999989322969728}\n",
      "[{'cost_min': 0.0005500500000000001, 'cost_max': 0.0005500500000000001, 'time_min': 30.3148230999941, 'time_max': 30.3148230999941, 'input_tokens': 35, 'output_tokens': 908, 'output_tokens_min': 908, 'output_tokens_max': 908, 'calls': 1, 'model': 'gpt-4o-mini', 'simulated': False, 'input_string': None, 'messages': None, 'output_string': 'The Riemann Hypothesis is one of the most famous and long-standing unsolved problems in mathematics, specifically in number theory and complex analysis. It is concerned with the distribution of prime numbers and is deeply connected to the properties of the Riemann zeta function.\\n\\n### Prerequisites\\n\\nTo understand the Riemann Hypothesis in detail, you should be familiar with the following concepts:\\n\\n1. **Complex Analysis**: Understanding complex functions, analytic continuation, and the concept of meromorphic functions.\\n2. **Number Theory**: Familiarity with prime numbers, the distribution of primes, and the concept of the Euler product.\\n3. **Fourier Analysis**: Basic knowledge of Fourier series and transforms, particularly in relation to periodic functions.\\n4. **Analytic Functions**: Understanding of poles, residues, and the argument principle.\\n\\n### The Riemann Zeta Function\\n\\nThe Riemann zeta function \\\\(\\\\zeta(s)\\\\) is defined for complex numbers \\\\(s\\\\) with real part greater than 1 by the series:\\n\\n\\\\[\\n\\\\zeta(s) = \\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^s}\\n\\\\]\\n\\nThis series converges for \\\\(\\\\text{Re}(s) > 1\\\\). The zeta function can be analytically continued to other values of \\\\(s\\\\) (except for \\\\(s = 1\\\\), where it has a simple pole) using various techniques, including the use of the Euler product formula:\\n\\n\\\\[\\n\\\\zeta(s) = \\\\prod_{p \\\\text{ prime}} \\\\frac{1}{1 - p^{-s}}\\n\\\\]\\n\\nfor \\\\(\\\\text{Re}(s) > 1\\\\). This product representation connects the zeta function to the distribution of prime numbers.\\n\\n### Analytic Continuation and Functional Equation\\n\\nThe zeta function can be analytically continued to the entire complex plane except for \\\\(s = 1\\\\). It satisfies a functional equation:\\n\\n\\\\[\\n\\\\zeta(s) = 2^s \\\\pi^{s-1} \\\\sin\\\\left(\\\\frac{\\\\pi s}{2}\\\\right) \\\\Gamma(1-s) \\\\zeta(1-s)\\n\\\\]\\n\\nwhere \\\\(\\\\Gamma(s)\\\\) is the gamma function. This functional equation relates values of the zeta function at \\\\(s\\\\) and \\\\(1-s\\\\).\\n\\n### Non-Trivial Zeros\\n\\nThe Riemann Hypothesis specifically concerns the non-trivial zeros of the zeta function, which are the solutions to the equation:\\n\\n\\\\[\\n\\\\zeta(s) = 0\\n\\\\]\\n\\nThe trivial zeros of the zeta function occur at the negative even integers: \\\\(s = -2, -4, -6, \\\\ldots\\\\). The non-trivial zeros are located in the critical strip where \\\\(0 < \\\\text{Re}(s) < 1\\\\).\\n\\n### The Riemann Hypothesis Statement\\n\\nThe Riemann Hypothesis asserts that all non-trivial zeros of the Riemann zeta function lie on the \"critical line\" in the complex plane, defined by:\\n\\n\\\\[\\n\\\\text{Re}(s) = \\\\frac{1}{2}\\n\\\\]\\n\\nIn other words, if \\\\(s = \\\\sigma + it\\\\) is a non-trivial zero of \\\\(\\\\zeta(s)\\\\), then the hypothesis states that:\\n\\n\\\\[\\n\\\\sigma = \\\\frac{1}{2}\\n\\\\]\\n\\n### Implications of the Riemann Hypothesis\\n\\nThe Riemann Hypothesis has profound implications for number theory, particularly in the distribution of prime numbers. The prime number theorem, which describes the asymptotic distribution of primes, can be refined using the Riemann Hypothesis. Specifically, it implies that the error term in the prime number theorem can be significantly improved.\\n\\n### Current Status\\n\\nAs of now, the Riemann Hypothesis remains unproven, despite extensive numerical evidence supporting it. Many non-trivial zeros have been computed, and all of them lie on the critical line, consistent with the hypothesis. The hypothesis is one of the seven \"Millennium Prize Problems,\" with a reward of one million dollars for a correct proof or counterexample.\\n\\n### Conclusion\\n\\nThe Riemann Hypothesis is a central question in mathematics that connects various fields, including number theory, complex analysis, and mathematical physics. Its resolution would not only advance our understanding of prime numbers but also have far-reaching consequences across mathematics.', 'description': None}, {'cost_min': 0.00032745, 'cost_max': 0.00032745, 'time_min': 4.519827699987218, 'time_max': 4.519827699987218, 'input_tokens': 131, 'output_tokens': 513, 'output_tokens_min': 513, 'output_tokens_max': 513, 'calls': 1, 'model': 'gpt-4o-mini', 'simulated': False, 'input_string': None, 'messages': None, 'output_string': 'The 2024 presidential election is poised to be a pivotal moment in American history, and there are compelling reasons to believe that Donald Trump will emerge as the winner. \\n\\nFirst and foremost, Trump\\'s base remains incredibly loyal and energized. Despite the controversies and challenges he has faced, his supporters have consistently demonstrated unwavering commitment. This loyalty is not just a fleeting sentiment; it is a deeply ingrained belief in his vision for America. In a political landscape where voter turnout can be the deciding factor, Trump\\'s ability to mobilize his base gives him a significant advantage.\\n\\nMoreover, the current political climate is ripe for Trump\\'s return. Economic concerns, including inflation and job security, are at the forefront of voters\\' minds. Many Americans feel disillusioned with the current administration\\'s handling of these issues. Trump has a proven track record of appealing to voters\\' economic anxieties, and his promises to restore jobs and stimulate growth resonate strongly with those who feel left behind. His message of \"Make America Great Again\" taps into a nostalgic yearning for a time when many felt more secure and prosperous.\\n\\nAdditionally, Trump\\'s media presence and ability to dominate the news cycle cannot be underestimated. He has a unique talent for capturing public attention, whether through rallies, social media, or interviews. This visibility not only keeps him relevant but also allows him to shape the narrative around the election. In an era where perception often outweighs reality, Trump\\'s ability to control the conversation gives him a strategic edge over his opponents.\\n\\nFurthermore, the Democratic Party faces its own internal challenges. With a divided electorate and varying opinions on key issues, the party may struggle to present a unified front against Trump. If the Democrats cannot effectively rally their base and present a compelling alternative, they risk handing Trump the opportunity to capitalize on their disarray.\\n\\nLastly, historical trends suggest that incumbents or former presidents often have an advantage in elections. Trump\\'s previous experience in office, combined with his name recognition and established political brand, positions him favorably against any challengers. Voters often gravitate towards familiarity, especially in uncertain times, and Trump\\'s status as a former president could sway undecided voters who prioritize stability.\\n\\nIn conclusion, the combination of Trump\\'s loyal base, the current political and economic climate, his media prowess, the challenges facing the Democratic Party, and historical trends all point to a strong likelihood that Donald Trump will be the 2024 presidential winner. His ability to connect with voters and address their concerns makes him a formidable candidate, and as the election approaches, it is clear that he is a force to be reckoned with.', 'description': None}, {'cost_min': 0.00042389999999999995, 'cost_max': 0.00042389999999999995, 'time_min': 5.153217800019775, 'time_max': 5.153217800019775, 'input_tokens': 650, 'output_tokens': 544, 'output_tokens_min': 544, 'output_tokens_max': 544, 'calls': 1, 'model': 'gpt-4o-mini', 'simulated': False, 'input_string': None, 'messages': None, 'output_string': \"The 2024 presidential election is shaping up to be a critical juncture for the United States, and there are several compelling reasons to believe that the winner will not be Donald Trump. \\n\\nFirst and foremost, the political landscape has evolved significantly since Trump's presidency. Many voters are seeking change and are disillusioned with the divisive politics that characterized his time in office. The growing demographic shifts in the electorate, particularly among younger voters and diverse communities, indicate a strong desire for a candidate who embodies inclusivity and progress. This shift could lead to a significant backlash against Trump, as voters may prioritize unity and a forward-looking vision over nostalgia for the past.\\n\\nMoreover, Trump's legal challenges and controversies continue to loom large. As he faces multiple indictments and ongoing investigations, these issues could alienate moderate voters who are concerned about the implications of his legal troubles. The perception of instability and chaos surrounding his candidacy may deter undecided voters who prioritize integrity and stability in leadership. In a time when many Americans are yearning for a sense of normalcy, Trump's legal entanglements could serve as a significant liability.\\n\\nAdditionally, the Democratic Party, despite its internal challenges, has a strong opportunity to present a compelling alternative to Trump. With a diverse field of candidates and a renewed focus on key issues such as healthcare, climate change, and social justice, the Democrats can effectively mobilize their base and appeal to independent voters. The party's ability to unite around a candidate who resonates with the electorate's concerns could prove to be a decisive factor in the election outcome.\\n\\nFurthermore, the impact of grassroots movements and activism cannot be underestimated. The rise of organizations focused on voter registration, turnout, and advocacy for progressive policies has energized many Americans who are eager for change. This grassroots momentum could translate into higher voter turnout, particularly among demographics that traditionally lean Democratic. If these movements successfully engage and mobilize voters, it could create a formidable challenge for Trump.\\n\\nLastly, historical trends indicate that elections often favor candidates who can adapt to the changing sentiments of the electorate. Trump's polarizing nature may hinder his ability to attract swing voters, especially in battleground states where elections are often decided by a small margin. If the opposition can effectively communicate a vision that resonates with the electorate's aspirations, it could lead to a decisive victory against Trump.\\n\\nIn conclusion, the combination of shifting demographics, Trump's legal challenges, the potential for a strong Democratic alternative, grassroots activism, and historical trends all suggest that the 2024 presidential winner is unlikely to be Donald Trump. As the election approaches, the desire for change and a unifying vision may ultimately prevail, paving the way for a candidate who can address the pressing issues facing the nation and inspire hope for the future.\", 'description': None}, {'cost_min': 0.00017565, 'cost_max': 0.00017565, 'time_min': 0.609430699958466, 'time_max': 0.609430699958466, 'input_tokens': 1167, 'output_tokens': 1, 'output_tokens_min': 1, 'output_tokens_max': 1, 'calls': 1, 'model': 'gpt-4o-mini', 'simulated': False, 'input_string': None, 'messages': None, 'output_string': {'A': 1.0677030272546973e-06, 'B': 0.9999989322969728}, 'description': None}]\n"
     ]
    }
   ],
   "source": [
    "d = SequentialDebate(\n",
    "    judge = Judge(),\n",
    "    debater_1 = Debater(),\n",
    "    debater_2 = Debater(),\n",
    ")\n",
    "dtrans = await d.run(ques, cost_log=ce, simulate=False)\n",
    "print(dtrans)\n",
    "print(ce.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to tokenize input_string None or messages None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\estimators\\llm_api_estimation.py:419\u001b[0m, in \u001b[0;36mLLM_API_Estimation._get_tokens\u001b[1;34m(model, input_tokens, output_tokens_min, output_tokens_max, input_string, messages, output_string)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m input_string \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_string \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m c \u001b[38;5;241m=\u001b[39m OpenConsultancy(\n\u001b[0;32m      2\u001b[0m     judge \u001b[38;5;241m=\u001b[39m Judge(),\n\u001b[0;32m      3\u001b[0m     consultant \u001b[38;5;241m=\u001b[39m Consultant(),\n\u001b[0;32m      4\u001b[0m     client\u001b[38;5;241m=\u001b[39mClient(),\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m ctrans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m c\u001b[38;5;241m.\u001b[39mrun(ques, cost_log\u001b[38;5;241m=\u001b[39mce, simulate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(ctrans)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(ce\u001b[38;5;241m.\u001b[39mitems)\n",
      "File \u001b[1;32mc:\\Users\\abhim\\Google Drive\\Gittable\\Code\\math_problems_debate\\solib\\protocols\\consultancy.py:167\u001b[0m, in \u001b[0;36mConsultancy.run\u001b[1;34m(self, question, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, question: Question, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Transcript:\n\u001b[0;32m    166\u001b[0m     transcript \u001b[38;5;241m=\u001b[39m Transcript(question, protocol\u001b[38;5;241m=\u001b[39mConsultancy)\n\u001b[1;32m--> 167\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoose_answer(question, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsultant_goes_first:\n\u001b[0;32m    169\u001b[0m         consultant_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsultant(answer, transcript, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abhim\\Google Drive\\Gittable\\Code\\math_problems_debate\\solib\\protocols\\variants\\consultancy.py:10\u001b[0m, in \u001b[0;36mOpenConsultancy.choose_answer\u001b[1;34m(self, question, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m auxillary_judge \u001b[38;5;241m=\u001b[39m Judge(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsultant\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m      9\u001b[0m transcript \u001b[38;5;241m=\u001b[39m Transcript(question)\n\u001b[1;32m---> 10\u001b[0m auxillary_judgement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m auxillary_judge(transcript, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     11\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m auxillary_judgement\u001b[38;5;241m.\u001b[39mprobabilities\n\u001b[0;32m     12\u001b[0m ans_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(probabilities, key\u001b[38;5;241m=\u001b[39mprobabilities\u001b[38;5;241m.\u001b[39mget)\n",
      "File \u001b[1;32mc:\\Users\\abhim\\Google Drive\\Gittable\\Code\\math_problems_debate\\solib\\protocols\\common.py:61\u001b[0m, in \u001b[0;36mJudge.__call__\u001b[1;34m(self, transcript, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, transcript: Transcript, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelf.TranscriptItem\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     60\u001b[0m     words_in_mouth \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m I judge that the answer is:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 61\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m get_llm_probs_async(\n\u001b[0;32m     62\u001b[0m         prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mformat(transcript\u001b[38;5;241m=\u001b[39mtranscript),\n\u001b[0;32m     63\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m     64\u001b[0m         return_probs_for\u001b[38;5;241m=\u001b[39mtranscript\u001b[38;5;241m.\u001b[39mquestion\u001b[38;5;241m.\u001b[39mpossible_answer_symbols,\n\u001b[0;32m     65\u001b[0m         words_in_mouth\u001b[38;5;241m=\u001b[39mwords_in_mouth,\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     67\u001b[0m     )\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTranscriptItem(probabilities\u001b[38;5;241m=\u001b[39mprobabilities)\n",
      "File \u001b[1;32mc:\\Users\\abhim\\Google Drive\\Gittable\\Code\\math_problems_debate\\solib\\llm_utils.py:582\u001b[0m, in \u001b[0;36mget_llm_probs_async\u001b[1;34m(return_probs_for, model, prompt, messages, input_string, system_message, words_in_mouth, top_logprobs, temperature, **kwargs)\u001b[0m\n\u001b[0;32m    576\u001b[0m model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    577\u001b[0m ai \u001b[38;5;241m=\u001b[39m get_llm(\n\u001b[0;32m    578\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    579\u001b[0m     use_async\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    580\u001b[0m     use_instructor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    581\u001b[0m )\n\u001b[1;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ai[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_probs_async\u001b[39m\u001b[38;5;124m\"\u001b[39m](\n\u001b[0;32m    583\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    584\u001b[0m     return_probs_for\u001b[38;5;241m=\u001b[39mreturn_probs_for,\n\u001b[0;32m    585\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m    586\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    587\u001b[0m     input_string\u001b[38;5;241m=\u001b[39minput_string,\n\u001b[0;32m    588\u001b[0m     system_message\u001b[38;5;241m=\u001b[39msystem_message,\n\u001b[0;32m    589\u001b[0m     words_in_mouth\u001b[38;5;241m=\u001b[39mwords_in_mouth,\n\u001b[0;32m    590\u001b[0m     top_logprobs\u001b[38;5;241m=\u001b[39mtop_logprobs,\n\u001b[0;32m    591\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    593\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\decorator.py:54\u001b[0m, in \u001b[0;36mcostly.<locals>.decorator.<locals>.async_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m simulate:\n\u001b[0;32m     49\u001b[0m     simulator_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     50\u001b[0m         k: v\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m costly_kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m signature(simulator)\u001b[38;5;241m.\u001b[39mparameters\n\u001b[0;32m     53\u001b[0m     } \u001b[38;5;241m|\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcost_log\u001b[39m\u001b[38;5;124m\"\u001b[39m: cost_log, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: description}\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msimulator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msimulator_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cost_log \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m cost_log\u001b[38;5;241m.\u001b[39mnew_item_async() \u001b[38;5;28;01mas\u001b[39;00m (item, timer):\n",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\simulators\\llm_simulator_faker.py:121\u001b[0m, in \u001b[0;36mLLM_Simulator_Faker.simulate_llm_call\u001b[1;34m(input_string, input_tokens, messages, model, response_model, cost_log, description)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel is required for tracking costs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cost_log\u001b[38;5;241m.\u001b[39mnew_item() \u001b[38;5;28;01mas\u001b[39;00m (item, _):\n\u001b[1;32m--> 121\u001b[0m         cost_item \u001b[38;5;241m=\u001b[39m \u001b[43mLLM_API_Estimation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cost_simulating\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# output_string=response, # not needed\u001b[39;49;00m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m         item\u001b[38;5;241m.\u001b[39mupdate(cost_item)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\estimators\\llm_api_estimation.py:464\u001b[0m, in \u001b[0;36mLLM_API_Estimation.get_cost_simulating\u001b[1;34m(model, input_tokens, output_tokens_min, output_tokens_max, input_string, messages, output_string, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cost_simulating\u001b[39m(\n\u001b[0;32m    454\u001b[0m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    462\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    463\u001b[0m     input_tokens, output_tokens_min, output_tokens_max \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 464\u001b[0m         \u001b[43mLLM_API_Estimation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_tokens_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_tokens_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_tokens_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_tokens_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     )\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LLM_API_Estimation\u001b[38;5;241m.\u001b[39m_get_cost_simulating_from_input_tokens_output_tokens(\n\u001b[0;32m    475\u001b[0m         input_tokens\u001b[38;5;241m=\u001b[39minput_tokens,\n\u001b[0;32m    476\u001b[0m         output_tokens_min\u001b[38;5;241m=\u001b[39moutput_tokens_min,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    483\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\estimators\\llm_api_estimation.py:427\u001b[0m, in \u001b[0;36mLLM_API_Estimation._get_tokens\u001b[1;34m(model, input_tokens, output_tokens_min, output_tokens_max, input_string, messages, output_string)\u001b[0m\n\u001b[0;32m    423\u001b[0m             input_tokens \u001b[38;5;241m=\u001b[39m LLM_API_Estimation\u001b[38;5;241m.\u001b[39mmessages_to_input_tokens(\n\u001b[0;32m    424\u001b[0m                 messages, model\n\u001b[0;32m    425\u001b[0m             )\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    428\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to tokenize input_string \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or messages \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessages\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         )\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_tokens_min \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m output_tokens_max \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to tokenize input_string None or messages None"
     ]
    }
   ],
   "source": [
    "c = OpenConsultancy(\n",
    "    judge = Judge(),\n",
    "    consultant = Consultant(),\n",
    "    client=Client(),\n",
    ")\n",
    "ctrans = await c.run(ques, cost_log=ce, simulate=True)\n",
    "print(ctrans)\n",
    "print(ce.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to tokenize input_string None or messages None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\estimators\\llm_api_estimation.py:419\u001b[0m, in \u001b[0;36mLLM_API_Estimation._get_tokens\u001b[1;34m(model, input_tokens, output_tokens_min, output_tokens_max, input_string, messages, output_string)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m input_string \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_string \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m c \u001b[38;5;241m=\u001b[39m OpenConsultancy(\n\u001b[0;32m      2\u001b[0m     judge \u001b[38;5;241m=\u001b[39m JustAskProbabilityJudge(),\n\u001b[0;32m      3\u001b[0m     consultant \u001b[38;5;241m=\u001b[39m Consultant(),\n\u001b[0;32m      4\u001b[0m     client\u001b[38;5;241m=\u001b[39mClient(),\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m ctrans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m c\u001b[38;5;241m.\u001b[39mrun(ques, cost_log\u001b[38;5;241m=\u001b[39mce, simulate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(ctrans)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(ce\u001b[38;5;241m.\u001b[39mitems)\n",
      "File \u001b[1;32mc:\\Users\\abhim\\Google Drive\\Gittable\\Code\\math_problems_debate\\solib\\protocols\\consultancy.py:167\u001b[0m, in \u001b[0;36mConsultancy.run\u001b[1;34m(self, question, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, question: Question, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Transcript:\n\u001b[0;32m    166\u001b[0m     transcript \u001b[38;5;241m=\u001b[39m Transcript(question, protocol\u001b[38;5;241m=\u001b[39mConsultancy)\n\u001b[1;32m--> 167\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoose_answer(question, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsultant_goes_first:\n\u001b[0;32m    169\u001b[0m         consultant_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsultant(answer, transcript, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abhim\\Google Drive\\Gittable\\Code\\math_problems_debate\\solib\\protocols\\variants\\consultancy.py:10\u001b[0m, in \u001b[0;36mOpenConsultancy.choose_answer\u001b[1;34m(self, question, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m auxillary_judge \u001b[38;5;241m=\u001b[39m Judge(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsultant\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m      9\u001b[0m transcript \u001b[38;5;241m=\u001b[39m Transcript(question)\n\u001b[1;32m---> 10\u001b[0m auxillary_judgement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m auxillary_judge(transcript, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     11\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m auxillary_judgement\u001b[38;5;241m.\u001b[39mprobabilities\n\u001b[0;32m     12\u001b[0m ans_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(probabilities, key\u001b[38;5;241m=\u001b[39mprobabilities\u001b[38;5;241m.\u001b[39mget)\n",
      "File \u001b[1;32mc:\\Users\\abhim\\Google Drive\\Gittable\\Code\\math_problems_debate\\solib\\protocols\\common.py:61\u001b[0m, in \u001b[0;36mJudge.__call__\u001b[1;34m(self, transcript, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, transcript: Transcript, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelf.TranscriptItem\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     60\u001b[0m     words_in_mouth \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m I judge that the answer is:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 61\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m get_llm_probs_async(\n\u001b[0;32m     62\u001b[0m         prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mformat(transcript\u001b[38;5;241m=\u001b[39mtranscript),\n\u001b[0;32m     63\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m     64\u001b[0m         return_probs_for\u001b[38;5;241m=\u001b[39mtranscript\u001b[38;5;241m.\u001b[39mquestion\u001b[38;5;241m.\u001b[39mpossible_answer_symbols,\n\u001b[0;32m     65\u001b[0m         words_in_mouth\u001b[38;5;241m=\u001b[39mwords_in_mouth,\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     67\u001b[0m     )\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTranscriptItem(probabilities\u001b[38;5;241m=\u001b[39mprobabilities)\n",
      "File \u001b[1;32mc:\\Users\\abhim\\Google Drive\\Gittable\\Code\\math_problems_debate\\solib\\llm_utils.py:582\u001b[0m, in \u001b[0;36mget_llm_probs_async\u001b[1;34m(return_probs_for, model, prompt, messages, input_string, system_message, words_in_mouth, top_logprobs, temperature, **kwargs)\u001b[0m\n\u001b[0;32m    576\u001b[0m model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    577\u001b[0m ai \u001b[38;5;241m=\u001b[39m get_llm(\n\u001b[0;32m    578\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    579\u001b[0m     use_async\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    580\u001b[0m     use_instructor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    581\u001b[0m )\n\u001b[1;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ai[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_probs_async\u001b[39m\u001b[38;5;124m\"\u001b[39m](\n\u001b[0;32m    583\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    584\u001b[0m     return_probs_for\u001b[38;5;241m=\u001b[39mreturn_probs_for,\n\u001b[0;32m    585\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m    586\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    587\u001b[0m     input_string\u001b[38;5;241m=\u001b[39minput_string,\n\u001b[0;32m    588\u001b[0m     system_message\u001b[38;5;241m=\u001b[39msystem_message,\n\u001b[0;32m    589\u001b[0m     words_in_mouth\u001b[38;5;241m=\u001b[39mwords_in_mouth,\n\u001b[0;32m    590\u001b[0m     top_logprobs\u001b[38;5;241m=\u001b[39mtop_logprobs,\n\u001b[0;32m    591\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    593\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\decorator.py:54\u001b[0m, in \u001b[0;36mcostly.<locals>.decorator.<locals>.async_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m simulate:\n\u001b[0;32m     49\u001b[0m     simulator_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     50\u001b[0m         k: v\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m costly_kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m signature(simulator)\u001b[38;5;241m.\u001b[39mparameters\n\u001b[0;32m     53\u001b[0m     } \u001b[38;5;241m|\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcost_log\u001b[39m\u001b[38;5;124m\"\u001b[39m: cost_log, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: description}\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msimulator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msimulator_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cost_log \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m cost_log\u001b[38;5;241m.\u001b[39mnew_item_async() \u001b[38;5;28;01mas\u001b[39;00m (item, timer):\n",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\simulators\\llm_simulator_faker.py:121\u001b[0m, in \u001b[0;36mLLM_Simulator_Faker.simulate_llm_call\u001b[1;34m(input_string, input_tokens, messages, model, response_model, cost_log, description)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel is required for tracking costs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cost_log\u001b[38;5;241m.\u001b[39mnew_item() \u001b[38;5;28;01mas\u001b[39;00m (item, _):\n\u001b[1;32m--> 121\u001b[0m         cost_item \u001b[38;5;241m=\u001b[39m \u001b[43mLLM_API_Estimation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cost_simulating\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# output_string=response, # not needed\u001b[39;49;00m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m         item\u001b[38;5;241m.\u001b[39mupdate(cost_item)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\estimators\\llm_api_estimation.py:464\u001b[0m, in \u001b[0;36mLLM_API_Estimation.get_cost_simulating\u001b[1;34m(model, input_tokens, output_tokens_min, output_tokens_max, input_string, messages, output_string, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cost_simulating\u001b[39m(\n\u001b[0;32m    454\u001b[0m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    462\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    463\u001b[0m     input_tokens, output_tokens_min, output_tokens_max \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 464\u001b[0m         \u001b[43mLLM_API_Estimation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_tokens_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_tokens_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_tokens_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_tokens_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     )\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LLM_API_Estimation\u001b[38;5;241m.\u001b[39m_get_cost_simulating_from_input_tokens_output_tokens(\n\u001b[0;32m    475\u001b[0m         input_tokens\u001b[38;5;241m=\u001b[39minput_tokens,\n\u001b[0;32m    476\u001b[0m         output_tokens_min\u001b[38;5;241m=\u001b[39moutput_tokens_min,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    483\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\abhim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\costly\\estimators\\llm_api_estimation.py:427\u001b[0m, in \u001b[0;36mLLM_API_Estimation._get_tokens\u001b[1;34m(model, input_tokens, output_tokens_min, output_tokens_max, input_string, messages, output_string)\u001b[0m\n\u001b[0;32m    423\u001b[0m             input_tokens \u001b[38;5;241m=\u001b[39m LLM_API_Estimation\u001b[38;5;241m.\u001b[39mmessages_to_input_tokens(\n\u001b[0;32m    424\u001b[0m                 messages, model\n\u001b[0;32m    425\u001b[0m             )\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    428\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to tokenize input_string \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or messages \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessages\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         )\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_tokens_min \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m output_tokens_max \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to tokenize input_string None or messages None"
     ]
    }
   ],
   "source": [
    "c = OpenConsultancy(\n",
    "    judge = JustAskProbabilityJudge(),\n",
    "    consultant = Consultant(),\n",
    "    client=Client(),\n",
    ")\n",
    "ctrans = await c.run(ques, cost_log=ce, simulate=True)\n",
    "print(ctrans)\n",
    "print(ce.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(ce.items))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
